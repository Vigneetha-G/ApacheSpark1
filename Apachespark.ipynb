{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "buy1mHChT8ts"
      },
      "outputs": [],
      "source": [
        "# 1. Install Java\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# 2. Download Spark 3.5.0 with Hadoop 3\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# 3. Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Install findspark\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "cqbP0gWIUBYf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"Colab-Spark\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "vXsGuc3OUxEo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "IIDPTabHU1NM",
        "outputId": "e828545f-cd3b-4bb3-f562-d92abb0aa196"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79498702fc50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://05aad96e7e25:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab-Spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To see spark jobs and DAGs\n",
        "spark.sparkContext.uiWebUrl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "z1qI713wVPEJ",
        "outputId": "b5d2bb50-50c5-4137-e9e3-54698f44641c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://05aad96e7e25:4040'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# Replace with your token\n",
        "!ngrok config add-authtoken YOUR_AUTHENTICATION_TOKEN\n",
        "# Connect to Spark UI (4040)\n",
        "spark_ui = ngrok.connect(4040)\n",
        "print(\"Spark UI link:\", spark_ui.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMtyKfB8VeNd",
        "outputId": "5acc41b6-f8b2-4c56-e9c9-31ccffd0e8c6",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-30T17:21:06+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark UI link: https://arlo-unscorching-grumbly.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "wO_1zyzeoz2R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "Ys_P20h5W7uQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3485ab0-ec56-43a6-8376-08a2be5106a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "sample_data  spark-3.5.0-bin-hadoop3  spark-3.5.0-bin-hadoop3.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sal.adaptive.enabled\",False)"
      ],
      "metadata": {
        "id": "jR6hjGrYpVw8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", True) \\\n",
        "    .option(\"inferSchema\", True) \\\n",
        "    .load(\"spark-3.5.0-bin-hadoop3/R/MegaMart.csv\")\n",
        "\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byrqpVo3pbLt",
        "outputId": "283bc893-215d-4786-9b34-d22ed153d926"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----------+----------+----------------+--------------------+--------+--------------+--------------+------------+\n",
            "|order_id|user_id|order_date|product_id|product_category|        product_name|quantity|price_per_unit|payment_method|order_status|\n",
            "+--------+-------+----------+----------+----------------+--------------------+--------+--------------+--------------+------------+\n",
            "|    1001|   U188|2025-04-20|      P940|         Fashion|            Sneakers|       2|         58.53|        PayPal|   Cancelled|\n",
            "|    1002|   U062|2025-04-16|      P794|         Fashion|             T-Shirt|       3|         83.76|           UPI|    Returned|\n",
            "|    1003|   U058|2025-04-18|      P326|         Fashion|          Sunglasses|       2|         78.85|        PayPal|  Processing|\n",
            "|    1004|   U011|2025-04-10|      P574|         Fashion|          Sunglasses|       5|         46.49|        PayPal|   Delivered|\n",
            "|    1005|   U003|2025-04-19|      P988|      Home Decor|         Photo Frame|       2|         78.61|        PayPal|    Returned|\n",
            "|    1006|   U017|2025-04-15|      P328|         Kitchen|           Knife Set|       4|         53.51|   Credit Card|    Returned|\n",
            "|    1007|   U129|2025-04-23|      P786|      Home Decor|          Wall Clock|       5|         12.71|   Credit Card|    Returned|\n",
            "|    1008|   U102|2025-04-15|      P101|      Home Decor|         Photo Frame|       1|          46.6|    Debit Card|   Cancelled|\n",
            "|    1009|   U040|2025-04-04|      P610|         Kitchen|             Toaster|       4|         35.87|   Credit Card|  Processing|\n",
            "|    1010|   U186|2025-04-29|      P354|         Kitchen|           Microwave|       1|         30.95|   Credit Card|  Processing|\n",
            "|    1011|   U168|2025-05-02|      P706|     Electronics|         USB-C Cable|       4|         18.79|        PayPal|  Processing|\n",
            "|    1012|   U148|2025-04-24|      P315|         Fashion|          Sunglasses|       5|         69.14|   Credit Card|  Processing|\n",
            "|    1013|   U140|2025-05-03|      P516|         Fashion|            Sneakers|       5|         90.64|   Credit Card|   Cancelled|\n",
            "|    1014|   U112|2025-04-18|      P111|           Books|Data Engineering 101|       1|         93.91|   Credit Card|   Cancelled|\n",
            "|    1015|   U184|2025-04-11|      P930|         Fashion|          Sunglasses|       1|          61.0|           UPI|   Cancelled|\n",
            "|    1016|   U025|2025-04-24|      P713|     Electronics|          Smartwatch|       2|         54.77|           UPI|    Returned|\n",
            "|    1017|   U021|2025-04-26|      P728|           Books|  Big Data Explained|       5|         13.42|        PayPal|   Delivered|\n",
            "|    1018|   U067|2025-04-15|      P650|     Electronics|      Wireless Mouse|       2|         18.72|    Debit Card|  Processing|\n",
            "|    1019|   U115|2025-05-03|      P973|         Kitchen|             Blender|       3|         35.68|    Debit Card|   Delivered|\n",
            "|    1020|   U159|2025-04-16|      P859|         Kitchen|             Blender|       4|         56.08|           UPI|  Processing|\n",
            "+--------+-------+----------+----------+----------------+--------------------+--------+--------------+--------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Narrow Transformations(1 stage,1 task)**"
      ],
      "metadata": {
        "id": "sO99TlaVp9N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1= df1.filter(col('product_name')=='Sneakers')"
      ],
      "metadata": {
        "id": "brwSHugZp9-X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df1.select('order_id','product_name')"
      ],
      "metadata": {
        "id": "kRqWc1CnqBtq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXhOGiObqYAV",
        "outputId": "51030612-4d09-4402-8876-7e0c66ed203a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+\n",
            "|order_id|product_name|\n",
            "+--------+------------+\n",
            "|    1001|    Sneakers|\n",
            "|    1013|    Sneakers|\n",
            "|    1026|    Sneakers|\n",
            "|    1039|    Sneakers|\n",
            "|    1155|    Sneakers|\n",
            "|    1175|    Sneakers|\n",
            "|    1190|    Sneakers|\n",
            "|    1195|    Sneakers|\n",
            "|    1233|    Sneakers|\n",
            "|    1267|    Sneakers|\n",
            "|    1281|    Sneakers|\n",
            "|    1325|    Sneakers|\n",
            "|    1330|    Sneakers|\n",
            "|    1349|    Sneakers|\n",
            "|    1362|    Sneakers|\n",
            "|    1379|    Sneakers|\n",
            "|    1442|    Sneakers|\n",
            "|    1457|    Sneakers|\n",
            "|    1480|    Sneakers|\n",
            "|    1494|    Sneakers|\n",
            "+--------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wide Transformation(1 stage,200 tasks)**"
      ],
      "metadata": {
        "id": "kXuTcnDqqLgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df1.groupBy('product_name').agg(count(col('order_id')))"
      ],
      "metadata": {
        "id": "zMMo6Y0YqFbX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tltloJfpqTiD",
        "outputId": "d77c9afb-f5d5-45ff-a621-f6b310b3296d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+\n",
            "|product_name|count(order_id)|\n",
            "+------------+---------------+\n",
            "|    Sneakers|             41|\n",
            "+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**JOINS**"
      ],
      "metadata": {
        "id": "dBIHNHphwZ3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.autoBroadCastJoinThreshold\",-1)\n",
        "spark.conf.set(\"spark.sal.adaptive.enabled\",False)"
      ],
      "metadata": {
        "id": "BG5wsR80wcmW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast"
      ],
      "metadata": {
        "id": "ijt-TlE5zkiq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create first Dataframe\n",
        "data1=[\n",
        "    (1,\"Alice\"),\n",
        "    (2,\"Bobby\"),\n",
        "    (3,\"Charlie\"),\n",
        "    (4,\"Don\"),\n",
        "    (5,\"Eva\")\n",
        "]\n",
        "df1=spark.createDataFrame(data1,[\"id\",\"name\"])\n",
        "\n",
        "#Create second DataFrame\n",
        "data2=[\n",
        "    (1,50000),\n",
        "    (2,60000),\n",
        "    (3,70000),\n",
        "    (6,90000)\n",
        "]\n",
        "df2=spark.createDataFrame(data2,[\"id\",\"salary\"])"
      ],
      "metadata": {
        "id": "cu4saIHCw-Cw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort merge Join\n",
        "df_join=df1.join(df2,df1['id']==df2['id'],'left')"
      ],
      "metadata": {
        "id": "QSBeDlLIxMkg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_join.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RWeHk3fyhot",
        "outputId": "c4d8d641-c893-4a36-e3d0-cebb8770a8cb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+----+------+\n",
            "| id|   name|  id|salary|\n",
            "+---+-------+----+------+\n",
            "|  1|  Alice|   1| 50000|\n",
            "|  2|  Bobby|   2| 60000|\n",
            "|  5|    Eva|NULL|  NULL|\n",
            "|  3|Charlie|   3| 70000|\n",
            "|  4|    Don|NULL|  NULL|\n",
            "+---+-------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#broad cast join\n",
        "# disable ->spark.conf.set(\"spark.sql.autoBroadCastJoinThreshold\",-1)\n",
        "#df_join_broadcast=df1.join(broadcast(df2),df1['id']==df2['id'],'left')"
      ],
      "metadata": {
        "id": "4rfY0hxg1j7d"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}