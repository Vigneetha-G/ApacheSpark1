{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "buy1mHChT8ts"
      },
      "outputs": [],
      "source": [
        "# 1. Install Java\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# 2. Download Spark 3.5.0 with Hadoop 3\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# 3. Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Install findspark\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "cqbP0gWIUBYf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"Colab-Spark\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "vXsGuc3OUxEo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "IIDPTabHU1NM",
        "outputId": "19076271-7f38-4b9c-db7d-a8fcd46a5610"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78be3cbfdfa0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d895f6773331:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab-Spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lazy Evaluation & Action**"
      ],
      "metadata": {
        "id": "axtee_VvVDLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To see spark jobs and DAGs\n",
        "spark.sparkContext.uiWebUrl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "z1qI713wVPEJ",
        "outputId": "ede3ba5b-f561-4213-c912-0b1f6ad108c0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://d895f6773331:4040'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# Replace with your token\n",
        "!ngrok config add-authtoken 33Ofpjn1uGGV5JZne7NM8uLDw0d_4pfoUSsGk6QRPEs9YaoUT\n",
        "\n",
        "# Connect to Spark UI (4040)\n",
        "spark_ui = ngrok.connect(4040)\n",
        "print(\"Spark UI link:\", spark_ui.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMtyKfB8VeNd",
        "outputId": "e53a12be-190f-4e7c-ec83-6663f15437f4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Spark UI link: https://arlo-unscorching-grumbly.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "wO_1zyzeoz2R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test DataFrame\n",
        "data = [\n",
        "       (\"Alice\",25,\"New York\"),\n",
        "       (\"Bob\",30,\"San Francisco\"),\n",
        "       (\"Charlie\",25,\"Chicago\")\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"name\",StringType(),True),\n",
        "    StructField(\"age\",IntegerType(),True),\n",
        "    StructField(\"city\",StringType(),True)\n",
        "])\n",
        "df= spark.createDataFrame(data,schema=schema)"
      ],
      "metadata": {
        "id": "Ys_P20h5W7uQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Narrow Transformations**"
      ],
      "metadata": {
        "id": "CmeH_o5tqhZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(col('city')=='New York')"
      ],
      "metadata": {
        "id": "H84bWCyRW83G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.select('city')"
      ],
      "metadata": {
        "id": "NoIZHNAzXRRT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdxK7JziouxB",
        "outputId": "ba29544a-0d84-4065-ade1-0952c7033cca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|    city|\n",
            "+--------+\n",
            "|New York|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.explain()"
      ],
      "metadata": {
        "id": "xOrajsfFXX1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c662b5e4-194e-467e-8b2b-82b29f06cec7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) Project [city#2]\n",
            "+- *(1) Filter (isnotnull(city#2) AND (city#2 = New York))\n",
            "   +- *(1) Scan ExistingRDD[name#0,age#1,city#2]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wide Transformations**"
      ],
      "metadata": {
        "id": "WmUxHzE0qnrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test DataFrame\n",
        "data = [\n",
        "       (\"Alice\",25,\"New York\"),\n",
        "       (\"Bob\",30,\"San Francisco\"),\n",
        "       (\"Charlie\",25,\"Chicago\")\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"name\",StringType(),True),\n",
        "    StructField(\"age\",IntegerType(),True),\n",
        "    StructField(\"city\",StringType(),True)\n",
        "])\n",
        "df= spark.createDataFrame(data,schema=schema)"
      ],
      "metadata": {
        "id": "zpr0vcaDr4VT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.groupBy('city').agg(max(col('age')))"
      ],
      "metadata": {
        "id": "wqE-gzHLqsi4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGk1CjNEr9Qi",
        "outputId": "cc7e7f59-62f5-4180-aa8a-62efcac5e3cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------+\n",
            "|         city|max(age)|\n",
            "+-------------+--------+\n",
            "|     New York|      25|\n",
            "|San Francisco|      30|\n",
            "|      Chicago|      25|\n",
            "+-------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHuJ44BUsJEa",
        "outputId": "a7f3b558-820e-4fd3-eb25-5b6ee0259a97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[city#14], functions=[max(age#13)])\n",
            "   +- Exchange hashpartitioning(city#14, 200), ENSURE_REQUIREMENTS, [plan_id=85]\n",
            "      +- HashAggregate(keys=[city#14], functions=[partial_max(age#13)])\n",
            "         +- Project [age#13, city#14]\n",
            "            +- Scan ExistingRDD[name#12,age#13,city#14]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Repartition and Coalesce**"
      ],
      "metadata": {
        "id": "EKFRmyINuvPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVtTeLujuupV",
        "outputId": "e65556ef-1689-4933-9830-371f7aa17d4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#repartition\n",
        "df=df.repartition(3)"
      ],
      "metadata": {
        "id": "tUArVtfvvOtV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coalesce\n",
        "df=df.coalesce(1)"
      ],
      "metadata": {
        "id": "gpyjpyudv0Aa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxO7mGpQv5gw",
        "outputId": "fbf0b98f-bcf4-4b73-f1f2-3303cf1e3755"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=true\n",
            "+- == Final Plan ==\n",
            "   Coalesce 1\n",
            "   +- ShuffleQueryStage 1\n",
            "      +- Exchange RoundRobinPartitioning(3), REPARTITION_BY_NUM, [plan_id=231]\n",
            "         +- *(2) HashAggregate(keys=[city#14], functions=[max(age#13)])\n",
            "            +- AQEShuffleRead coalesced\n",
            "               +- ShuffleQueryStage 0\n",
            "                  +- Exchange hashpartitioning(city#14, 200), ENSURE_REQUIREMENTS, [plan_id=207]\n",
            "                     +- *(1) HashAggregate(keys=[city#14], functions=[partial_max(age#13)])\n",
            "                        +- *(1) Project [age#13, city#14]\n",
            "                           +- *(1) Scan ExistingRDD[name#12,age#13,city#14]\n",
            "+- == Initial Plan ==\n",
            "   Coalesce 1\n",
            "   +- Exchange RoundRobinPartitioning(3), REPARTITION_BY_NUM, [plan_id=194]\n",
            "      +- HashAggregate(keys=[city#14], functions=[max(age#13)])\n",
            "         +- Exchange hashpartitioning(city#14, 200), ENSURE_REQUIREMENTS, [plan_id=192]\n",
            "            +- HashAggregate(keys=[city#14], functions=[partial_max(age#13)])\n",
            "               +- Project [age#13, city#14]\n",
            "                  +- Scan ExistingRDD[name#12,age#13,city#14]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}